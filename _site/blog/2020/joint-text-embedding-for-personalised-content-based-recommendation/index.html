<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Avhirup Chakraborty | Joint Text Embedding for Personalised Content-based Recommendation</title>
  <meta name="description" content="I'm passionate about data science and programming . I believe I am programmer first and data scientist second. I believe in delivering, clean, intuitive, well-designed. and scalable data science solutions. I seek to challenge myself, learn and solve world disrupting problems.">

  <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicon.ico">

  <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
  <link rel="canonical" href="http://localhost:4000/blog/2020/joint-text-embedding-for-personalised-content-based-recommendation/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Avhirup</strong> Chakraborty
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="http://localhost:4000/">about</a>

        <!-- Blog -->
        <a class="page-link" href="http://localhost:4000/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="http://localhost:4000/projects/">projects</a>
          
        
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="http://localhost:4000/assets/pdf/Avhirup_Search_Resume.pdf">resume</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Joint Text Embedding for Personalised Content-based Recommendation</h1>
    <p class="post-meta">April 6, 2020</p>
  </header>

  <article class="post-content">
    <h3 id="tldr">TLDR</h3>
<p>Learning user and text embedding for <strong>personalised recommendation of new textual items</strong>. Embedding are learnt by treating the problem as a <strong>ranking problem</strong> and increasing the proximity score for each positive user-item pair and vice-versa for negative user-item pair. Item are embedded using their associated text. Text embedding are also learnt during the learning to rank process. To tackle the problem of unseen text and reduce overfitting,an <strong>unsupervised pretrained text embedding component</strong> is added to text embedding module.</p>

<p><a href="https://arxiv.org/abs/1706.01084">Link to the paper</a></p>

<h3 id="introduction">Introduction</h3>
<p>It is very common to encounter the problem of personalised recommendation for relatively new item without prior user interaction (Cold start problem). For many use cases, the only meta data associated with the item is text. For example; Quora question recommendation where every day new set questions are populated. Google News recommendation based on news article text to the user.</p>

<p>Learning a joint text embedding (user and item) for such items is useful to let use compare user and item similarity, while also facilitating to solve the cold start problem. Users and text item can be simulataneously embedded into a latent space where preferences can be depicted by a dot product.</p>

<h3 id="problem-statement">Problem Statement</h3>
<p>Personalised recommendation for completely new items with text information available.</p>

<h3 id="methodology">Methodology</h3>
<p>The task is to learn joint embedding for user and item. The paper treats it as a ranking problem where item which is more likely to be clicked/liked needs to be ranked higher. During this process of learning to rank,we learn both user as well as the text embedding.</p>

<div class="img_row">
    <img class="col three" src="/assets/img/joint-text-embedding-for-personalised-content-based-recommendation/approach.jpg" width="719" height="308" />
</div>

<p>The proximity score between the user and item pair (i,j) is computed as a dot product \(s_{ij} = u_i \f{x_j}\). The objective is to rank userâ€™s interest articles higher than those he/she is not interested in.
The score difference between positive and negative items is maximized, leading to the pairwise ranking loss function as <br />
\(\mathcal{L}=\mathbb{E}_{(i, p, n) \sim \mathcal{D}}\left[-\log \sigma\left(s_{i,p}-s_{i,n}\right)\right]\)
Each triplet is drawn from some predefined data distribution and \(\sigma\) is sigmoid function.</p>

<p>Now, \(\f(x_j)\) encodes text to an embedding. There are two parts to this function.</p>
<ul>
  <li>Unsupervised pretrained text embedding (h2)
    <ul>
      <li>This could be any embedding techinque(Word2vec, LSTM , CNN) pretrained on the item text corpus or any general corpus. This is reponsible to encode new unknown text, solving the cold start problem.</li>
    </ul>
  </li>
  <li>Supervised text embedding (h1):
    <ul>
      <li>This textual embedding is learnt during the training process.
h1 and h2 are combined using a single layer NN.</li>
    </ul>
  </li>
</ul>

<h3 id="evaluation">Evaluation</h3>
<p>For evaluation MAP (Mean Average Precision) and average AUC used. Below are the results on different datasets.</p>

<div class="img_row">
    <img class="col three" src="/assets/img/joint-text-embedding-for-personalised-content-based-recommendation/evaluation.jpg" width="732" height="300" />
</div>

  </article>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Avhirup Chakraborty.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="http://localhost:4000/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="http://localhost:4000/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
